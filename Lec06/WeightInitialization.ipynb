{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모든 뉴런이 아무것도 하지 않는다.\n",
    "* 모든 뉴런이 같은 행동을 한다.\n",
    "* 모든 뉴런이 똑같이 업데이트되서 모두 같아진다.\n",
    "* 0이 아닌 상수를 넣어도 뉴런들이 같은 행동을 하기 때문에 좋지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* gaussian with zero mean and 1e-2 standard deviation\n",
    "* W = 0.01 * np.random.randn(D,H)\n",
    "* 0.01 : scaling\n",
    "* 깊은 차원이면 표준편차가 급격하게 줄어들어 0이 된다.\n",
    "* 결국 activation이 0이 되고\n",
    "* gradient 계산시에도 너무 작은 값이 나오는 문제(Vanishing Gradient)가 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight 크기를 늘려봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* standard gaussin with 1 표준편차\n",
    "* 가중치들이 점점 커져서 결국 뉴런들이 포화된다.\n",
    "* 포화되서 gradient가 0이된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 적절한 크기?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* W = np.random.randn(fan_in, fan_out) / np.sqrt(fan_in)\n",
    "* 큰값이면 줄여주고 작은 값이면 늘려주는 방법\n",
    "* 구해지는 값이 Wx에서 W의 열과 x의 행에 영향을 받기 때문에  결국 갯수에 따라 나눠줘야 한다.\n",
    "* 입력 분포에 맞게 끔 scaling 해주는 방법\n",
    "* 단 ReLU 쓰는 경우, 모델이 반을 죽이기 때문에 variance가 정확하지않다. 이에 따른 해결법에 관한 논문이 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
