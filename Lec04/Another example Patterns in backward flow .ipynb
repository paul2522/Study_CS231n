{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another example & Patterns in backward flow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 역전파가 유용한지 더 알아보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(w,x) = 1 / (1 + e <sup>-(w<sub>0</sub>x<sub>0</sub>+w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>)</sup>)  \n",
    "computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"equation1.png\" width = \"50%\" height = \"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* f(x) = e<sup>x</sup>      - df/dx = e<sup>x</sup>\n",
    "* f<sub>a</sub>(x) = ax     - df/dx = a\n",
    "* f(x) = 1/x                - df/dx = -1/x<sup>2</sup>\n",
    "* f<sub>c</sub>(x) = c + x  - df/dx = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gradient 계산하기\n",
    "* upstream gradient * local gradient (chain rule)\n",
    "1. 1.00\n",
    "2. -1/(1.37<sup>2</sup>) * 1.00 = -0.53\n",
    "3. 0.53 * 1 = -0.53\n",
    "4. -0.53  * e<sup>-1</sup> = -2.0\n",
    "5. -0.2 * -1 = 0.2\n",
    "6. 0.2 * 1, 0.2 * 1 (two branches)\n",
    "7. 0.2 * 1, 0.2 * 1\n",
    "8. 0.2 * -1 = -0.2, 0.2 * 2 = 0.4\n",
    "9. 0.2 * -2 = -0.6, 0.2 * -3 = -0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"equation2.png\" width = \"50%\" height = \"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x) = 1/(1 + e<sup>-x</sup>)  \n",
    "df(x)/dx = e<sup>-x</sup> / (1+e<sup>-x</sup>)<sup>2</sup> = (1 - f(x))*f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 노드들 간에 그룹화해서 도함수가 표현되는 다른 함수로 만들 수 있다.  \n",
    "그룹화하면 더 압축되고 간단한 그래프로 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저렇게 파란 부분을 sigmoid로 묶어주면  \n",
    "0.73을 sigmoid의 도함수에 넣어주면 gradient가 된다.  \n",
    "0.73 * (1 - 0.73) = 0.1971 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"equation3.png\" width = \"50%\" height = \"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  add gate : gradient 분배해줌\n",
    "*  max gate : gradient 경로 잡아줌\n",
    "*  mul gate : gradient 바꿔줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 노드에서 여러 노드로 갈라지는 경우는 각 upstream gradient의 합이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"equation4.png\" width = \"50%\" height = \"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞 노드를 바뀌면 양쪽 노드에 영향이 가고 역전파시 양쪽 노드의 gradient가 앞 노드로 가기 때문에 합한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tensorflowvenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "505d9b51f9342e4d9e78ab3b64f587cb99890dcce609b88967bdb38d69ddf9f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
