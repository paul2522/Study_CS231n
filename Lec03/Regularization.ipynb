{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization (정규화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L = 0으로 만드는 W은 유일하지않다.  \n",
    "2W도 L = 0으로 만든다.  \n",
    "그러므로 모델이 W를 선택할 때 모호하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L(W)의 앞의 식은 training data에 맞추는 W를 찾는다.  \n",
    "하지만 우리의 최종 목적은 training data가 아닌 test data에 대한 예측이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파란색 지점은 training data에 완전히 맞춰진 결과\n",
    "추가로 나온 녹색 지점을 test data로 놓고보면 파란 선은 완전히 틀림  \n",
    "그래서 새롭게 그린 녹색 선을 더 선호합니다.  \n",
    "이러한 문제 Overfitting 를 해결하기 위해 정규화를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L(W) 식에 추가로 람다R(W)를 더합니다. 이것이 정규화 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Occam's razor(오컴의 면도날)  \n",
    "무엇인가를 이해하려고 할때, 불필요한 정보를 얻지 않는 것이 사실 또는 정확한 설명에 도달하는데 가장 좋은 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CS231N  \n",
    "관측한 것에서 여러가지 가정들을 넣을 때, 가장 간단한 것을 선호한다. 왜냐하면 미래의 다른 것들을 설명할때 쉬우니까."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래서 보통의 손실 함수는 Data loss 와 정규화 loss 두 개를 말한다.  \n",
    "R(W) 앞의 람다는 Data loss와 정규화 loss 사이의 균형을 잡아준다.  \n",
    "그래서 이 하이퍼 파라미터인 람다 설정이 되게 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question : 그래서 파란선에서 녹색선으로 어떻게 보내는데?  \n",
    "* Answer : 대충 얘기하자면 우리가 회귀분석할때 원래의 고차원의 다항식을 회귀를 통해 저차원의 다항식으로 계산하는 것, 단 제대로 예측할때"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 방법 1 : 모델을 제한시켜서 애초에 더 복잡한 모델이 안되게 하는 방법\n",
    "* 방법 2 : 고차원의 다항식으로 가려고 할 때 간단한 패널티를 준다 - 고차원의 다항식을 쓰고 싶으면 이 패널티를 감수해라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화의 방식  \n",
    "* L2 : 유클리드 거리(흔히 아는 거리 계산, 제곱)\n",
    "* L1 : 절대값\n",
    "* Elastic Net(L1+L2)\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결국 정규화란 모델이 너무 training data에만 맞춰가지 않도록 모델의 복잡성에 패널티를 준다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question : 그래서 L2 정규화로 어떻게 측정하는데\n",
    "* Anser : X와 2개의 W를 두자. X 는 그냥 (1,1,1,1)이고 W1 = (1,0,0,0) 이고 W2 = (0.25,0.25,0.25,0.25) 일때  \n",
    "* 선형 회귀에서 W*X 이므로 W1, W2 둘다 1이다.\n",
    "* 근데 여기서 L2 regression을 누가 더 선호할까?\n",
    "* W2가 더 선호, W2의 L2가 더 작기 때문\n",
    "* W2가 다른 모든 x의 값에 나눠서 영향을 주기 때문에 x 값이 변함에 따라 한가지 값만 비교하는 것에 비해더 robust 하다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L1 : 미분시 상수\n",
    "* L2 : 미분시 상수 * W\n",
    "* L1은 sparse matrix가 만들어진다.(0이 많은 행렬)\n",
    "* L2은 coarse maxtrix가 만들어진다.(다같이 증감하는 행렬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L1과 L2의 함수를 그려볼때 양수 값만 보자면, y = x와 y = x^2로 볼 때, 보통 이상치는 높은 절대값을 가지는 위치에 있다(정규 분포에 따라).\n",
    "* 고로 높은 절대값을 가지는 위치의 이상치 a의 loss를 보면 L1 = a, L2 = a^2 로 L2가 더 이상치에 크게 반응한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
